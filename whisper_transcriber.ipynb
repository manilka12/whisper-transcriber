{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manilka12/whisper-transcriber/blob/main/whisper_transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96kvih9mXkNN"
      },
      "source": [
        "\n",
        "## **How to use**\n",
        "1. Click Runtime -> Run all and wait\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1zwGAsr4sIgd"
      },
      "outputs": [],
      "source": [
        "# @markdown # **[Optional]** Access data in Google Drive üíæ\n",
        "# @markdown Enter a Google Drive path and run this cell to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Faster Whisper\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Whisper Audio Transcription Tool\n",
        "# Author: Manilka Chamuditha\n",
        "# GitHub: https://github.com/manilka12/whisper-transcriber\n",
        "\n",
        "# @title # üéôÔ∏è Whisper Audio Transcription Tool {\"display-mode\":\"form\"}\n",
        "#@markdown This notebook helps you transcribe audio from various sources using OpenAI's Whisper model (via faster-whisper).\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## üì¶ Setup Dependencies\n",
        "#@markdown Run this cell to install required packages\n",
        "\n",
        "# Install dependencies with progress indicators\n",
        "import sys\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "def install_with_progress(package):\n",
        "    \"\"\"Install package with progress indicator\"\"\"\n",
        "    display(HTML(f\"<p>Installing {package}...</p>\"))\n",
        "    !pip install -q {package}\n",
        "    clear_output(wait=True)\n",
        "    display(HTML(f\"<p>‚úÖ {package} installed</p>\"))\n",
        "\n",
        "# Install required packages\n",
        "install_with_progress(\"faster-whisper\")\n",
        "install_with_progress(\"yt-dlp\")\n",
        "install_with_progress(\"tqdm\")\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import shutil\n",
        "import logging\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display, Markdown, YouTubeVideo, HTML\n",
        "from google.colab import files\n",
        "import requests\n",
        "from urllib.parse import urlsplit\n",
        "\n",
        "# Setup basic logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    datefmt='%H:%M:%S')\n",
        "logger = logging.getLogger(\"WhisperTranscriber\")\n",
        "\n",
        "# Check for CUDA availability and setup device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "logger.info(f\"Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    !sudo apt-get update -qq > /dev/null\n",
        "    !sudo apt install -qq nvidia-cuda-toolkit > /dev/null\n",
        "    logger.info(f\"CUDA installed. GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "#@title # üß† Model Selection\n",
        "#@markdown Select the Whisper model variant to use for transcription\n",
        "\n",
        "#@markdown ---\n",
        "model_size = 'large-v3' #@param ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2', 'large-v3']\n",
        "compute_type = \"float16\" #@param {type:\"string\"} ['float16', 'int8_float16', 'int8']\n",
        "#@markdown ---\n",
        "#@markdown **Memory usage**: Larger models provide better accuracy but require more GPU memory\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "try:\n",
        "    from faster_whisper import WhisperModel\n",
        "    model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "    logger.info(f\"‚úÖ Model '{model_size}' loaded successfully\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"‚ùå Failed to load model: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "#@title # üì∫ Media Source Selection\n",
        "#@markdown Choose the source of your video/audio file for transcription\n",
        "\n",
        "#@markdown ---\n",
        "# Pre-check if there are media files already in the working directory\n",
        "def check_for_media_files():\n",
        "    \"\"\"Check if media files already exist in the workspace\"\"\"\n",
        "    content_dir = Path(\"/content\")\n",
        "    audio_extensions = [\".wav\", \".mp3\", \".ogg\", \".opus\", \".aac\", \".flac\", \".m4a\"]\n",
        "    video_extensions = [\".mp4\", \".mkv\", \".mov\", \".avi\", \".wmv\", \".flv\", \".webm\", \".3gp\", \".mpeg\"]\n",
        "    supported_extensions = audio_extensions + video_extensions\n",
        "\n",
        "    media_files = []\n",
        "    for file_path in content_dir.iterdir():\n",
        "        if file_path.is_file() and file_path.suffix.lower() in supported_extensions:\n",
        "            media_files.append(file_path)\n",
        "\n",
        "    return media_files\n",
        "\n",
        "existing_media = check_for_media_files()\n",
        "if existing_media:\n",
        "    existing_files_str = \"\\n\".join([f\"- {file.name}\" for file in existing_media])\n",
        "    display(Markdown(f\"üìÅ **Media files already found in workspace:**\\n{existing_files_str}\"))\n",
        "\n",
        "source_type = \"Auto-detect\" #@param ['Auto-detect', 'YouTube','Google Drive','Direct Download URL', 'Manual Upload']\n",
        "#@markdown **Auto-detect** will use any media files already in the workspace.\n",
        "#@markdown If none found, it will prompt for upload.\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### üé¨ YouTube Options\n",
        "youtube_url = \"\" #@param {type:\"string\"}\n",
        "download_audio_only = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### üìÅ Google Drive Options\n",
        "drive_path = \"my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown If using a folder, all media files will be processed\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### üåê Direct Download Options\n",
        "download_url = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### üö® No media files detected?\n",
        "#@markdown If needed, upload files in the **Manual Upload** option or choose another source.\n",
        "\n",
        "class MediaProcessor:\n",
        "    \"\"\"Class to handle different media sources and processing\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.media_files = []\n",
        "        self.audio_extensions = [\".wav\", \".mp3\", \".ogg\", \".opus\", \".aac\", \".flac\", \".m4a\"]\n",
        "        self.video_extensions = [\".mp4\", \".mkv\", \".mov\", \".avi\", \".wmv\", \".flv\", \".webm\", \".3gp\", \".mpeg\"]\n",
        "        self.supported_extensions = self.audio_extensions + self.video_extensions\n",
        "\n",
        "        # Create output directory\n",
        "        self.output_dir = Path(\"transcribed_texts\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Create temp directory for processing\n",
        "        self.temp_dir = Path(tempfile.mkdtemp())\n",
        "\n",
        "    def process_youtube(self, url, audio_only=True):\n",
        "        \"\"\"Download audio from YouTube URL\"\"\"\n",
        "        try:\n",
        "            display(Markdown(f\"‚¨áÔ∏è Downloading from YouTube: `{url}`\"))\n",
        "\n",
        "            import yt_dlp\n",
        "            ydl_opts = {\n",
        "                'format': 'm4a/bestaudio/best' if audio_only else 'bestvideo+bestaudio',\n",
        "                'outtmpl': f'{self.temp_dir}/%(id)s.%(ext)s',\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "                'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'wav',\n",
        "                    'preferredquality': '192',\n",
        "                }] if audio_only else []\n",
        "            }\n",
        "\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(url, download=True)\n",
        "                if 'entries' in info:  # Playlist\n",
        "                    for entry in info['entries']:\n",
        "                        file_path = Path(f\"{self.temp_dir}/{entry['id']}.wav\" if audio_only else f\"{self.temp_dir}/{entry['id']}.{entry['ext']}\")\n",
        "                        self.media_files.append(file_path)\n",
        "                        display(Markdown(f\"‚úÖ Downloaded: **{entry['title']}**\"))\n",
        "                else:  # Single video\n",
        "                    file_path = Path(f\"{self.temp_dir}/{info['id']}.wav\" if audio_only else f\"{self.temp_dir}/{info['id']}.{info['ext']}\")\n",
        "                    self.media_files.append(file_path)\n",
        "                    display(Markdown(f\"‚úÖ Downloaded: **{info['title']}**\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå YouTube download failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def process_drive(self, path, drive_already_mounted=True):\n",
        "        \"\"\"Process files from Google Drive\"\"\"\n",
        "        if not drive_already_mounted:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "\n",
        "        drive_path = Path('/content/drive/MyDrive') / Path(path.lstrip(\"/\"))\n",
        "\n",
        "        if not drive_path.exists():\n",
        "            logger.error(f\"‚ùå Path does not exist: {drive_path}\")\n",
        "            return\n",
        "\n",
        "        if drive_path.is_dir():\n",
        "            display(Markdown(f\"üìÅ Processing directory: `{drive_path}`\"))\n",
        "            for file_path in drive_path.glob(\"**/*\"):\n",
        "                if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:\n",
        "                    local_path = self.temp_dir / file_path.name\n",
        "                    shutil.copy(file_path, local_path)\n",
        "                    self.media_files.append(local_path)\n",
        "                    display(Markdown(f\"‚úÖ Added: **{file_path.name}**\"))\n",
        "        else:\n",
        "            if drive_path.suffix.lower() in self.supported_extensions:\n",
        "                local_path = self.temp_dir / drive_path.name\n",
        "                shutil.copy(drive_path, local_path)\n",
        "                self.media_files.append(local_path)\n",
        "                display(Markdown(f\"‚úÖ Added: **{drive_path.name}**\"))\n",
        "            else:\n",
        "                logger.error(f\"‚ùå Unsupported file type: {drive_path}\")\n",
        "\n",
        "    def process_direct_download(self, url):\n",
        "        \"\"\"Download media from direct URL\"\"\"\n",
        "        try:\n",
        "            display(Markdown(f\"‚¨áÔ∏è Downloading from URL: `{url}`\"))\n",
        "            response = requests.get(url, stream=True)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                logger.error(f\"‚ùå Download failed with status code: {response.status_code}\")\n",
        "                return\n",
        "\n",
        "            filename = urlsplit(url).path.split(\"/\")[-1]\n",
        "            if not any(filename.lower().endswith(ext) for ext in self.supported_extensions):\n",
        "                logger.warning(f\"‚ö†Ô∏è File may not be a supported media type: {filename}\")\n",
        "\n",
        "            file_path = self.temp_dir / filename\n",
        "\n",
        "            # Download with progress bar\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            block_size = 1024  # 1 Kibibyte\n",
        "\n",
        "            t = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "            with open(file_path, 'wb') as f:\n",
        "                for data in response.iter_content(block_size):\n",
        "                    t.update(len(data))\n",
        "                    f.write(data)\n",
        "            t.close()\n",
        "\n",
        "            self.media_files.append(file_path)\n",
        "            display(Markdown(f\"‚úÖ Downloaded: **{filename}**\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Direct download failed: {str(e)}\")\n",
        "\n",
        "    def process_manual_upload(self):\n",
        "        \"\"\"Process manually uploaded files\"\"\"\n",
        "        try:\n",
        "            display(Markdown(f\"üì§ Upload files using the button below:\"))\n",
        "\n",
        "            # Ask user to upload files\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            for filename, content in uploaded.items():\n",
        "                if any(filename.lower().endswith(ext) for ext in self.supported_extensions):\n",
        "                    file_path = self.temp_dir / filename\n",
        "                    with open(file_path, 'wb') as f:\n",
        "                        f.write(content)\n",
        "                    self.media_files.append(file_path)\n",
        "                    display(Markdown(f\"‚úÖ Uploaded: **{filename}**\"))\n",
        "                else:\n",
        "                    logger.warning(f\"‚ö†Ô∏è Skipping unsupported file: {filename}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Manual upload processing failed: {str(e)}\")\n",
        "\n",
        "    def use_existing_files(self, file_list):\n",
        "        \"\"\"Use files that already exist in the workspace\"\"\"\n",
        "        try:\n",
        "            for file_path in file_list:\n",
        "                target_path = self.temp_dir / file_path.name\n",
        "                shutil.copy(file_path, target_path)\n",
        "                self.media_files.append(target_path)\n",
        "                display(Markdown(f\"‚úÖ Using existing file: **{file_path.name}**\"))\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Error processing existing files: {str(e)}\")\n",
        "\n",
        "    def convert_to_audio(self):\n",
        "        \"\"\"Convert video files to audio for processing\"\"\"\n",
        "        for i, file_path in enumerate(self.media_files[:]):\n",
        "            if file_path.suffix.lower() in self.video_extensions:\n",
        "                display(Markdown(f\"üîÑ Converting video to audio: **{file_path.name}**\"))\n",
        "\n",
        "                # Define output audio path\n",
        "                audio_path = file_path.with_suffix(\".wav\")\n",
        "\n",
        "                # Convert video to audio using ffmpeg\n",
        "                try:\n",
        "                    result = subprocess.run(\n",
        "                        [\"ffmpeg\", \"-i\", str(file_path), \"-vn\", \"-acodec\", \"pcm_s16le\",\n",
        "                         \"-ar\", \"16000\", \"-ac\", \"1\", str(audio_path), \"-y\", \"-loglevel\", \"error\"],\n",
        "                        stdout=subprocess.PIPE,\n",
        "                        stderr=subprocess.PIPE,\n",
        "                        check=True\n",
        "                    )\n",
        "\n",
        "                    # Replace video with audio in the list\n",
        "                    self.media_files[i] = audio_path\n",
        "                    display(Markdown(f\"‚úÖ Converted to audio: **{audio_path.name}**\"))\n",
        "\n",
        "                    # Optionally remove the original video file to save space\n",
        "                    os.remove(file_path)\n",
        "\n",
        "                except subprocess.CalledProcessError as e:\n",
        "                    logger.error(f\"‚ùå FFmpeg conversion failed: {e.stderr.decode('utf-8')}\")\n",
        "                    # Keep the original file in the list\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up temporary files\"\"\"\n",
        "        try:\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "            logger.info(\"üßπ Temporary files cleaned up\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Cleanup failed: {str(e)}\")\n",
        "\n",
        "# Process media based on selected source\n",
        "processor = MediaProcessor()\n",
        "\n",
        "try:\n",
        "    if source_type == \"Auto-detect\":\n",
        "        existing_media = check_for_media_files()\n",
        "        if existing_media:\n",
        "            processor.use_existing_files(existing_media)\n",
        "        else:\n",
        "            display(Markdown(\"‚ö†Ô∏è **No media files found in workspace. Please upload:**\"))\n",
        "            processor.process_manual_upload()\n",
        "\n",
        "    elif source_type == \"YouTube\":\n",
        "        if not youtube_url:\n",
        "            display(Markdown(\"‚ö†Ô∏è **Please provide a YouTube URL**\"))\n",
        "        else:\n",
        "            processor.process_youtube(youtube_url, download_audio_only)\n",
        "\n",
        "    elif source_type == \"Google Drive\":\n",
        "        if not drive_path:\n",
        "            display(Markdown(\"‚ö†Ô∏è **Please provide a Google Drive path**\"))\n",
        "        else:\n",
        "            processor.process_drive(drive_path)\n",
        "\n",
        "    elif source_type == \"Direct Download URL\":\n",
        "        if not download_url:\n",
        "            display(Markdown(\"‚ö†Ô∏è **Please provide a download URL**\"))\n",
        "        else:\n",
        "            processor.process_direct_download(download_url)\n",
        "\n",
        "    elif source_type == \"Manual Upload\":\n",
        "        processor.process_manual_upload()\n",
        "\n",
        "    # Convert videos to audio for processing\n",
        "    processor.convert_to_audio()\n",
        "\n",
        "    # Summary of files to be processed\n",
        "    if processor.media_files:\n",
        "        display(Markdown(f\"## üìã Files to be processed ({len(processor.media_files)}):\"))\n",
        "        for file in processor.media_files:\n",
        "            display(Markdown(f\"- **{file.name}**\"))\n",
        "    else:\n",
        "        display(Markdown(\"‚ö†Ô∏è **No media files found to process**\"))\n",
        "\n",
        "except Exception as e:\n",
        "    display(Markdown(f\"‚ùå **Error:** {str(e)}\"))\n",
        "\n",
        "#@title # üöÄ Transcription Settings\n",
        "#@markdown Configure the transcription process\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## üåç Language Settings\n",
        "language = \"en\" #@param [\"auto\", \"en\", \"zh\", \"de\", \"es\", \"ru\", \"ko\", \"fr\", \"ja\", \"pt\", \"tr\", \"pl\", \"ca\", \"nl\", \"ar\", \"sv\", \"it\", \"id\", \"hi\", \"fi\", \"vi\", \"he\", \"uk\", \"el\", \"ms\", \"cs\", \"ro\", \"da\", \"hu\", \"ta\", \"no\", \"th\", \"ur\", \"hr\", \"bg\", \"lt\", \"la\", \"mi\", \"ml\", \"cy\", \"sk\", \"te\", \"fa\", \"lv\", \"bn\", \"sr\", \"az\", \"sl\", \"kn\", \"et\", \"mk\", \"br\", \"eu\", \"is\", \"hy\", \"ne\", \"mn\", \"bs\", \"kk\", \"sq\", \"sw\", \"gl\", \"mr\", \"pa\", \"si\", \"km\", \"sn\", \"yo\", \"so\", \"af\", \"oc\", \"ka\", \"be\", \"tg\", \"sd\", \"gu\", \"am\", \"yi\", \"lo\", \"uz\", \"fo\", \"ht\", \"ps\", \"tk\", \"nn\", \"mt\", \"sa\", \"lb\", \"my\", \"bo\", \"tl\", \"mg\", \"as\", \"tt\", \"haw\", \"ln\", \"ha\", \"ba\", \"jw\", \"su\"] {allow-input: true}\n",
        "#@markdown Choose language or set to \"auto\" for automatic detection\n",
        "\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown Optional: Guide the model with an initial prompt (e.g., \"This is a medical lecture about cardiology.\")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## ‚öôÔ∏è Advanced Settings\n",
        "beam_size = 10 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown Higher values = better quality but slower processing\n",
        "\n",
        "word_level_timestamps = False #@param {type:\"boolean\"}\n",
        "#@markdown Generate timestamps for each word instead of sentences\n",
        "\n",
        "vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown Voice Activity Detection: filter out non-speech parts\n",
        "\n",
        "vad_filter_min_silence_ms = 50 #@param {type:\"integer\"}\n",
        "#@markdown Minimum silence duration in milliseconds for VAD filtering\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## üìÑ Output Settings\n",
        "output_format = \"Text (.txt)\" #@param [\"Text (.txt)\", \"Subtitles (.srt)\", \"Both\"]\n",
        "#@markdown Choose output format for transcriptions\n",
        "\n",
        "include_timestamps = False #@param {type:\"boolean\"}\n",
        "#@markdown Include timestamps in text output\n",
        "\n",
        "include_confidence = False #@param {type:\"boolean\"}\n",
        "#@markdown Include model confidence scores in the output\n",
        "\n",
        "show_live_transcription = True #@param {type:\"boolean\"}\n",
        "#@markdown Show transcription in real-time as it happens\n",
        "\n",
        "live_display_lines = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown Number of lines to show in live transcription window\n",
        "\n",
        "def seconds_to_timecode(seconds, format=\"srt\"):\n",
        "    \"\"\"Convert seconds to formatted timecode\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    seconds %= 3600\n",
        "    minutes = int(seconds // 60)\n",
        "    seconds %= 60\n",
        "    milliseconds = int((seconds % 1) * 1000)\n",
        "    seconds = int(seconds)\n",
        "\n",
        "    if format == \"srt\":\n",
        "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "    elif format == \"vtt\":\n",
        "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}\"\n",
        "    else:\n",
        "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "#@title # üé¨ Run Transcription\n",
        "#@markdown Start the transcription process for all processed files\n",
        "\n",
        "# Create a live transcription display area\n",
        "if show_live_transcription:\n",
        "    live_display = HTML(\n",
        "        f\"\"\"\n",
        "        <div style=\"border:1px solid #ddd; padding:10px; height:{24*live_display_lines}px; overflow-y:auto; margin-bottom:5px; background-color:#2d2d2d; font-family:monospace; white-space:pre-wrap; color:#ffffff;\">\n",
        "        <div id=\"live-transcription\"></div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    display(live_display)\n",
        "\n",
        "# Check if we have media files to process\n",
        "if not processor.media_files:\n",
        "    display(Markdown(\"‚ö†Ô∏è **No media files found to process. Please run the Media Source Selection cell first.**\"))\n",
        "else:\n",
        "    # Create timestamp for this batch\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    batch_dir = processor.output_dir / f\"batch_{timestamp}\"\n",
        "    batch_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Process each file\n",
        "    for file_idx, audio_path in enumerate(processor.media_files):\n",
        "        display(Markdown(f\"## üîÑ Processing file {file_idx+1}/{len(processor.media_files)}: **{audio_path.name}**\"))\n",
        "\n",
        "        try:\n",
        "            # Set up progress display\n",
        "            progress_html = HTML(\n",
        "                \"\"\"\n",
        "                <div style=\"width:100%; background-color:#f0f0f0; border-radius:5px;\">\n",
        "                    <div id=\"transcription-progress\" style=\"background-color:#4CAF50; width:0%; height:20px; border-radius:5px;\"></div>\n",
        "                </div>\n",
        "                <p id=\"transcription-status\">Starting transcription...</p>\n",
        "                \"\"\"\n",
        "            )\n",
        "            display(progress_html)\n",
        "\n",
        "            def update_progress(progress, message):\n",
        "                display(HTML(\n",
        "                    f\"\"\"\n",
        "                    <script>\n",
        "                        document.getElementById('transcription-progress').style.width = '{progress}%';\n",
        "                        document.getElementById('transcription-status').textContent = '{message}';\n",
        "                    </script>\n",
        "                    \"\"\"\n",
        "                ))\n",
        "\n",
        "            def update_live_transcription(text):\n",
        "                if show_live_transcription:\n",
        "                    display(HTML(\n",
        "                        f\"\"\"\n",
        "                        <script>\n",
        "                            var liveDiv = document.getElementById('live-transcription');\n",
        "                            liveDiv.innerHTML = \"{text}\";\n",
        "                            liveDiv.parentElement.scrollTop = liveDiv.parentElement.scrollHeight;\n",
        "                            liveDiv.style.color = \"#ffffff\"; // Ensure text remains white\n",
        "                        </script>\n",
        "                        \"\"\"\n",
        "                    ))\n",
        "\n",
        "            # Start transcription\n",
        "            update_progress(10, \"Loading model and analyzing audio...\")\n",
        "\n",
        "            # Recent segments for live display\n",
        "            class TranscriptionState:\n",
        "                def __init__(self):\n",
        "                    self.recent_segments = []\n",
        "\n",
        "            # Create an instance of the state holder\n",
        "            state = TranscriptionState()\n",
        "\n",
        "            # Callback for live transcription\n",
        "            def process_segment(segment):\n",
        "                # Add the new segment\n",
        "                state.recent_segments.append(segment.text.strip())\n",
        "                # Keep only the most recent lines\n",
        "                if len(state.recent_segments) > live_display_lines:\n",
        "                    state.recent_segments = state.recent_segments[-live_display_lines:]\n",
        "                # Update the display\n",
        "                display_text = \"\\n\".join(state.recent_segments)\n",
        "                display_text = display_text.replace('\"', '\\\\\"').replace('\\n', '\\\\n')\n",
        "                update_live_transcription(display_text)\n",
        "\n",
        "            # Run transcription\n",
        "            segments, info = model.transcribe(\n",
        "                str(audio_path),\n",
        "                beam_size=beam_size,\n",
        "                language=None if language == \"auto\" else language,\n",
        "                initial_prompt=initial_prompt if initial_prompt else None,\n",
        "                word_timestamps=word_level_timestamps,\n",
        "                vad_filter=vad_filter,\n",
        "                vad_parameters=dict(min_silence_duration_ms=vad_filter_min_silence_ms)\n",
        "            )\n",
        "\n",
        "            # Convert generator to list so we can iterate multiple times if needed\n",
        "            segment_list = []\n",
        "            for segment in segments:\n",
        "                segment_list.append(segment)\n",
        "                if show_live_transcription:\n",
        "                    process_segment(segment)\n",
        "                update_progress(50 + int(len(segment_list) % 10), \"Transcription in progress...\")\n",
        "\n",
        "            update_progress(90, \"Finalizing transcription...\")\n",
        "\n",
        "            # Determine output formats\n",
        "            formats = []\n",
        "            if output_format == \"Text (.txt)\" or output_format == \"Both\":\n",
        "                formats.append(\"txt\")\n",
        "            if output_format == \"Subtitles (.srt)\" or output_format == \"Both\":\n",
        "                formats.append(\"srt\")\n",
        "\n",
        "            # Display detected language info\n",
        "            display(Markdown(f\"üåç Detected language: **{info.language}** (probability: {info.language_probability:.2f})\"))\n",
        "\n",
        "            # Process the transcription for each output format\n",
        "            for format in formats:\n",
        "                output_file_name = f\"{audio_path.stem}.{format}\"\n",
        "                output_file_path = batch_dir / output_file_name\n",
        "\n",
        "                update_progress(95, f\"Writing {format.upper()} output...\")\n",
        "\n",
        "                with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "                    if format == \"txt\":\n",
        "                        # For TXT: Write continuous text without timestamps by default\n",
        "                        if word_level_timestamps:\n",
        "                            for segment in segment_list:\n",
        "                                for i, word in enumerate(segment.words):\n",
        "                                    text = word.word\n",
        "\n",
        "                                    if include_timestamps:\n",
        "                                        f.write(f\"[{seconds_to_timecode(word.start, 'txt')}] \")\n",
        "\n",
        "                                    if include_confidence:\n",
        "                                        text += f\" ({word.probability:.2f})\"\n",
        "\n",
        "                                    f.write(f\"{text}\")\n",
        "                                    if i < len(segment.words) - 1:\n",
        "                                        f.write(\" \")\n",
        "                                f.write(\"\\n\")\n",
        "                        else:\n",
        "                            for segment in segment_list:\n",
        "                                text = segment.text.strip()\n",
        "\n",
        "                                if include_timestamps:\n",
        "                                    f.write(f\"[{seconds_to_timecode(segment.start, 'txt')}-{seconds_to_timecode(segment.end, 'txt')}] \")\n",
        "\n",
        "                                if include_confidence:\n",
        "                                    text += f\" ({segment.avg_logprob:.2f})\"\n",
        "\n",
        "                                f.write(f\"{text}\\n\")\n",
        "\n",
        "                    elif format == \"srt\":\n",
        "                        # For SRT: Write subtitle format\n",
        "                        index = 1\n",
        "                        if word_level_timestamps:\n",
        "                            for segment in segment_list:\n",
        "                                for word in segment.words:\n",
        "                                    f.write(f\"{index}\\n\")\n",
        "                                    f.write(f\"{seconds_to_timecode(word.start)} --> {seconds_to_timecode(word.end)}\\n\")\n",
        "\n",
        "                                    text_line = word.word\n",
        "                                    if include_confidence:\n",
        "                                        text_line = f\"{text_line} ({word.probability:.2f})\"\n",
        "\n",
        "                                    f.write(f\"{text_line}\\n\\n\")\n",
        "                                    index += 1\n",
        "                        else:\n",
        "                            for segment in segment_list:\n",
        "                                f.write(f\"{index}\\n\")\n",
        "                                f.write(f\"{seconds_to_timecode(segment.start)} --> {seconds_to_timecode(segment.end)}\\n\")\n",
        "\n",
        "                                text_line = segment.text.strip()\n",
        "                                if include_confidence:\n",
        "                                    text_line = f\"{text_line} ({segment.avg_logprob:.2f})\"\n",
        "\n",
        "                                f.write(f\"{text_line}\\n\\n\")\n",
        "                                index += 1\n",
        "\n",
        "                display(Markdown(f\"‚úÖ Created {format.upper()} file: **{output_file_name}**\"))\n",
        "\n",
        "            update_progress(100, \"Transcription completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            display(Markdown(f\"‚ùå **Error transcribing {audio_path.name}**: {str(e)}\"))\n",
        "            logger.error(f\"Transcription error: {str(e)}\", exc_info=True)\n",
        "\n",
        "    # Create a zip file of all outputs\n",
        "    zip_file_path = batch_dir.parent / f\"transcribed_texts_{timestamp}.zip\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in batch_dir.glob(\"*\"):\n",
        "            zipf.write(file_path, arcname=file_path.name)\n",
        "\n",
        "    # Provide download links\n",
        "    display(Markdown(f\"## üì• Download Results\"))\n",
        "    display(Markdown(f\"* [Download ZIP of all transcriptions]({zip_file_path})\"))\n",
        "\n",
        "    # Clean up\n",
        "    processor.cleanup()\n",
        "\n",
        "    # Offer to download directly through Colab\n",
        "    display(Markdown(f\"**Or download through Colab:**\"))\n",
        "    files.download(str(zip_file_path))"
      ],
      "metadata": {
        "id": "nw-ppuEJPElZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}